# ðŸ” Deepfake Detector - AI-Powered Deepfake Detection System

A production-ready full-stack application that uses deep learning to detect whether uploaded images are authentic or deepfakes.

## ðŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Quick Start](#quick-start)
- [Installation](#installation)
- [Usage](#usage)
- [Training](#training)
- [Deployment](#deployment)
- [API Documentation](#api-documentation)
- [Model Details](#model-details)
- [Project Structure](#project-structure)

## Overview

### Features

âœ… **AI-Powered Detection**: Uses EfficientNet/ResNet neural networks for binary classification
âœ… **Real-Time Analysis**: Fast inference with GPU acceleration support
âœ… **Confidence Scoring**: Provides confidence percentage for predictions
âœ… **Visualization**: Grad-CAM heatmaps showing model focus areas
âœ… **Database Logging**: Stores all predictions with timestamps
âœ… **Clean UI**: Modern, responsive React dashboard
âœ… **REST API**: FastAPI backend with comprehensive endpoints
âœ… **Docker Support**: Containerized deployment ready
âœ… **Security**: File validation, size limits, CORS handling

### Classification Output

| Prediction | Meaning |
|------------|---------|
| **Real** | Image appears authentic with no signs of manipulation |
| **Deepfake** | Image shows signs of facial manipulation or synthesis |

## Architecture

### System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (React)                     â”‚
â”‚  - Image Upload & Preview                              â”‚
â”‚  - Real-time Analysis Display                          â”‚
â”‚  - Confidence Bars & Results                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTP/REST
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Backend API (FastAPI)                      â”‚
â”‚  - POST /predict - Image Analysis                      â”‚
â”‚  - GET /health - Health Check                          â”‚
â”‚  - GET /model-info - Model Info                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚            â”‚            â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”    â”Œâ”€â”€â”€â–¼â”€â”€â”    â”Œâ”€â”€â”€â–¼â”€â”€â”
    â”‚Model â”‚    â”‚Grad- â”‚    â”‚Data- â”‚
    â”‚Infer â”‚    â”‚CAM   â”‚    â”‚base  â”‚
    â”‚ence  â”‚    â”‚      â”‚    â”‚      â”‚
    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

#### Backend
- **Framework**: FastAPI (async Python web framework)
- **ML Framework**: PyTorch
- **Image Processing**: PIL, OpenCV
- **Database**: SQLite (Development), PostgreSQL (Production)
- **Server**: Uvicorn (ASGI server)

#### Frontend
- **Framework**: React 18
- **HTTP Client**: Axios
- **Styling**: CSS3 + Tailwind CSS
- **Icons**: React Icons

#### Model
- **Architecture**: EfficientNet-B0 (default) or ResNet50
- **Pretrained Weights**: ImageNet-1K
- **Input Size**: 224Ã—224 pixels
- **Output**: Binary classification (Real/Deepfake)

#### Deployment
- **Containerization**: Docker & Docker Compose
- **Cloud Platforms**: AWS (EC2), Railway, Render

## Quick Start

### Prerequisites

- Python 3.9+
- Node.js 16+
- Docker & Docker Compose (for Docker setup)
- CUDA 11.8+ (optional, for GPU acceleration)

### Option 1: Docker Compose (Recommended)

```bash
# Clone/extract project
cd deepfake-detector

# Start both services
docker-compose -f docker/docker-compose.yml up --build

# Access:
# Frontend: http://localhost:3000
# Backend: http://localhost:8000
# API Docs: http://localhost:8000/docs
```

### Option 2: Local Development

#### Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Create .env file
cp .env.example .env

# Run server
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

Backend will be available at `http://localhost:8000`

#### Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Start development server
npm start
```

Frontend will open at `http://localhost:3000`

## Installation

### Detailed Backend Setup

```bash
# 1. Navigate to backend
cd backend

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate

# 3. Upgrade pip
pip install --upgrade pip

# 4. Install dependencies
pip install -r requirements.txt

# 5. Create uploads and weights directories
mkdir -p uploads weights

# 6. Configure environment
cp .env.example .env
# Edit .env with your settings

# 7. Run migrations (if using PostgreSQL)
# SQLite database will be created automatically
```

### Detailed Frontend Setup

```bash
# 1. Navigate to frontend
cd frontend

# 2. Install dependencies
npm install

# 3. Create .env file
cat > .env << EOF
REACT_APP_API_URL=http://localhost:8000
EOF

# 4. Install additional packages if needed
npm install axios react-icons
```

## Usage

### Running the Application

#### Development Mode

```bash
# Terminal 1: Run Backend
cd backend
source venv/bin/activate
python main.py
# or
uvicorn main:app --reload --port 8000

# Terminal 2: Run Frontend
cd frontend
npm start
```

#### Production Mode

```bash
# Using Docker Compose
docker-compose -f docker/docker-compose.yml up -d

# Access on:
# http://localhost:3000 (Frontend)
# http://localhost:8000 (API)
```

### Using the Web Interface

1. **Upload Image**: Click or drag image (JPG/PNG, max 10MB)
2. **Analyze**: Click "Analyze Image" button
3. **View Results**:
   - Prediction (Real/Deepfake)
   - Confidence score (0-100%)
   - Model visualization
   - Analysis explanation

### API Usage Examples

#### Predict Image

```bash
# Using cURL
curl -X POST "http://localhost:8000/predict" \
  -H "accept: application/json" \
  -F "file=@image.jpg"

# Using Python
import requests

with open('image.jpg', 'rb') as f:
    response = requests.post(
        'http://localhost:8000/predict',
        files={'file': f}
    )
    print(response.json())
```

#### Response Format

```json
{
  "prediction": "Real",
  "confidence": 87.50,
  "explanation": "Grad-CAM heatmap generated",
  "filename": "image.jpg",
  "model": "efficientnet-b0",
  "device": "cuda",
  "grad_cam_available": true
}
```

#### Health Check

```bash
curl http://localhost:8000/health

# Response:
# {"status": "healthy", "app": "Deepfake Detector API", "version": "1.0.0"}
```

#### Model Info

```bash
curl http://localhost:8000/model-info

# Response includes model parameters and device info
```

## Training

### Dataset Preparation

The model is trained on facial image datasets. Recommended public datasets:

#### 1. **FaceForensics**
- Size: ~370GB (compressed)
- Faces: 1,000 original actors
- 5 manipulation types: Face2Face, FaceSwap, NeuralTextures, DeepFacelab, Deepfake
- Download: https://github.com/ondyari/FaceForensics

#### 2. **Celeb-DF**
- Size: ~405.7GB
- Faces: 500+ celebrities
- Deepfakes: 5,639 high-quality
- Download: https://github.com/yuezunli/celeb-df

### Directory Structure for Training

```
data/
â”œâ”€â”€ real/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”œâ”€â”€ image2.png
â”‚   â””â”€â”€ ...
â””â”€â”€ deepfake/
    â”œâ”€â”€ fake1.jpg
    â”œâ”€â”€ fake2.png
    â””â”€â”€ ...
```

### Training Script

```bash
cd models/training

# Basic training
python train.py --data-dir ../../data --epochs 20

# Advanced options
python train.py \
  --data-dir ../../data \
  --model efficientnet-b0 \
  --epochs 20 \
  --batch-size 32 \
  --learning-rate 0.001 \
  --output ../../weights/deepfake_model.pth \
  --device cuda

# ResNet50 model
python train.py \
  --data-dir ../../data \
  --model resnet50 \
  --epochs 20 \
  --output ../../weights/resnet_model.pth
```

### Training Parameters

| Parameter | Value | Description |
|-----------|-------|-------------|
| Batch Size | 32 | Images per batch |
| Learning Rate | 0.001 | Adam optimizer learning rate |
| Epochs | 20 | Training iterations |
| Input Size | 224Ã—224 | Image dimensions |
| Optimizer | Adam | Adaptive learning rate |
| Loss Function | CrossEntropyLoss | Classification loss |

### Expected Performance

- **Accuracy**: 95-99% (depends on dataset quality)
- **Training Time**: 4-8 hours (per epoch, batch size 32, GPU)
- **Model Size**: ~100-200 MB

### Resume Training

To continue training from checkpoint:

```python
# Modify train.py to load from checkpoint
trainer = DeepfakeDetectorTrainer(
    model_name="efficientnet-b0",
    device="cuda",
)
# Load weights
trainer.model.load_state_dict(torch.load('weights/deepfake_model.pth'))
trainer.train(train_loader, val_loader, epochs=20)
```

## Deployment

### Local Machine

Already covered in Quick Start section.

### Docker Deployment

```bash
# Build images
docker build -f docker/Dockerfile.backend -t deepfake-detector-backend .
docker build -f docker/Dockerfile.frontend -t deepfake-detector-frontend .

# Run containers
docker run -p 8000:8000 deepfake-detector-backend
docker run -p 3000:3000 deepfake-detector-frontend

# Or use Docker Compose
docker-compose -f docker/docker-compose.yml up
```

### AWS EC2 Deployment

```bash
# 1. Launch EC2 instance
# - Ubuntu 22.04 LTS
# - Instance type: t3.medium+ (for GPU: g4dn.xlarge)
# - Security group: Allow ports 80, 443, 8000, 3000

# 2. SSH into instance
ssh -i "key.pem" ubuntu@<instance-ip>

# 3. Install Docker and Docker Compose
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# 4. Clone project and run
git clone <repo-url>
cd deepfake-detector
docker-compose -f docker/docker-compose.yml up -d

# 5. Setup reverse proxy (Nginx)
# Configure to proxy requests to localhost:8000 and localhost:3000
```

### Railway Deployment

```bash
# 1. Install Railway CLI
npm i -g @railway/cli

# 2. Login
railway login

# 3. Create project
railway init

# 4. Set environment variables
railway variables set REACT_APP_API_URL=https://your-backend-url

# 5. Deploy
railway up
```

### Render Deployment

**Backend:**
1. Connect GitHub repo
2. Create Web Service
3. Build Command: `pip install -r backend/requirements.txt`
4. Start Command: `uvicorn main:app --host 0.0.0.0 --port $PORT`

**Frontend:**
1. Create Static Site
2. Build Command: `cd frontend && npm install && npm run build`
3. Publish Directory: `frontend/build`

### Environment Variables for Production

```
DEBUG=False
DEVICE=cuda  # or cpu
MAX_FILE_SIZE_MB=10
DATABASE_URL=postgresql://user:password@host/db
CORS_ORIGINS=["https://yourdomain.com"]
```

## API Documentation

### Interactive API Docs

Available at `http://localhost:8000/docs` (Swagger UI)

### Endpoints

#### POST /predict
Analyze uploaded image

**Request:**
- Content-Type: `multipart/form-data`
- Body: file (image/jpeg or image/png)

**Response:**
```json
{
  "prediction": "Real|Deepfake",
  "confidence": 0.0-100.0,
  "explanation": "string",
  "filename": "string",
  "model": "string",
  "device": "string",
  "grad_cam_available": true|false
}
```

**Status Codes:**
- 200: Success
- 400: Invalid file type or no file
- 413: File too large
- 500: Server error

#### GET /health
Health check endpoint

**Response:**
```json
{
  "status": "healthy",
  "app": "Deepfake Detector API",
  "version": "1.0.0"
}
```

#### GET /model-info
Get model information

**Response:**
```json
{
  "model_name": "efficientnet-b0",
  "device": "cuda",
  "model_path": "weights/deepfake_model.pth",
  "parameters": {
    "total_parameters": 4000000,
    "trainable_parameters": 4000000
  }
}
```

## Model Details

### EfficientNet-B0 (Default)

- **Architecture**: Compound scaling of baseline EfficientNet
- **Parameters**: ~4M
- **Input Size**: 224Ã—224
- **Pretrained**: ImageNet-1K
- **Advantages**:
  - Fast inference
  - Lower memory usage
  - Good accuracy
  - Efficient for edge devices

### ResNet50

- **Architecture**: 50-layer Residual Network
- **Parameters**: ~25M
- **Input Size**: 224Ã—224
- **Pretrained**: ImageNet-1K
- **Advantages**:
  - Higher accuracy potential
  - Well-established architecture
  - Extensive research
  - Good for CPU inference

### Grad-CAM Visualization

**How it works:**
1. Forward pass through network
2. Compute gradients of target class w.r.t. feature maps
3. Weight activation maps by gradients
4. Generate visual heatmap

**Interpretation:**
- Red regions: Model focuses on these areas
- Blue regions: Model ignores these areas
- Helps identify if model is manipulating faces correctly

## Project Structure

```
deepfake-detector/
â”œâ”€â”€ backend/                      # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py            # Configuration settings
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ routes.py        # API endpoints
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ detector.py      # Model inference
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ image_processing.py
â”‚   â”‚       â”œâ”€â”€ database.py
â”‚   â”‚       â””â”€â”€ grad_cam.py
â”‚   â”œâ”€â”€ main.py                  # FastAPI app entry point
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ frontend/                     # React frontend
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Header.js
â”‚   â”‚   â”‚   â”œâ”€â”€ ImageUploader.js
â”‚   â”‚   â”‚   â”œâ”€â”€ Results.js
â”‚   â”‚   â”‚   â””â”€â”€ ConfidenceBar.js
â”‚   â”‚   â”œâ”€â”€ App.js
â”‚   â”‚   â”œâ”€â”€ App.css
â”‚   â”‚   â”œâ”€â”€ index.js
â”‚   â”‚   â””â”€â”€ index.css
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ .env
â”‚   â””â”€â”€ tailwind.config.js
â”‚
â”œâ”€â”€ models/                       # ML models
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ inference.py         # Inference script
â”‚   â””â”€â”€ training/
â”‚       â””â”€â”€ train.py             # Training script
â”‚
â”œâ”€â”€ weights/                      # Model weights (download)
â”‚   â””â”€â”€ deepfake_model.pth
â”‚
â”œâ”€â”€ docker/                       # Docker files
â”‚   â”œâ”€â”€ Dockerfile.backend
â”‚   â”œâ”€â”€ Dockerfile.frontend
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ SETUP.md
â”‚   â”œâ”€â”€ API.md
â”‚   â””â”€â”€ DEPLOYMENT.md
â”‚
â”œâ”€â”€ README.md                     # This file
â””â”€â”€ .gitignore
```

## Troubleshooting

### Issue: Model not loading

**Solution:**
```bash
# Check if weights file exists
ls -lh weights/

# Download from official source or train custom model
python models/training/train.py --data-dir data
```

### Issue: GPU not detected

**Solution:**
```bash
# Check CUDA availability
python -c "import torch; print(torch.cuda.is_available())"

# Use CPU instead (edit .env)
DEVICE=cpu
```

### Issue: CORS errors

**Solution:**
```bash
# Update CORS settings in config.py
CORS_ORIGINS = ["http://localhost:3000", "your-frontend-url"]
```

### Issue: Memory error during inference

**Solution:**
```bash
# Reduce image size or model size
# Change model to EfficientNet-B0 (lighter)
# Or use CPU inference
```

## Performance Metrics

### Inference Time

| Model | Device | Time |
|-------|--------|------|
| EfficientNet-B0 | GPU (RTX 3080) | 10-30ms |
| EfficientNet-B0 | CPU | 100-200ms |
| ResNet50 | GPU | 15-40ms |
| ResNet50 | CPU | 200-400ms |

### Memory Usage

| Model | GPU Memory | CPU Memory |
|-------|-----------|-----------|
| EfficientNet-B0 | ~500MB | ~1GB |
| ResNet50 | ~2GB | ~2.5GB |

## Security Considerations

### File Validation
- Supported formats: JPG, PNG only
- File size limit: 10MB (configurable)
- Magic number validation

### API Security
- CORS protection
- Input validation
- Rate limiting (recommended)
- HTTPS in production

### Database Security
- SQLite for development
- PostgreSQL for production with credentials
- Connection pooling
- SQL injection prevention (ORM)

## Contributing

Guidelines for contributions:
1. Create feature branch
2. Follow code style
3. Test thoroughly
4. Submit pull request

## License

MIT License - See LICENSE file

## Support

For issues, questions, or suggestions:
- Open GitHub issue
- Email: support@deepfakedetector.com
- Documentation: https://deepfakedetector.com/docs

## References

- EfficientNet: https://arxiv.org/abs/1905.11946
- Grad-CAM: https://arxiv.org/abs/1610.02055
- FaceForensics++: https://arxiv.org/abs/1901.08971
- Celeb-DF: https://arxiv.org/abs/1909.06596

---

**Last Updated**: February 2026
**Version**: 1.0.0
